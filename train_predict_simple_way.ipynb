{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6518855c-84c1-4eee-a0c8-d50ecb5cdd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d15849bc-fc80-46e0-8ce3-35a11ee9aedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumberSequenceDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A simple dataset that teaches the model to count.\n",
    "    Sequence: [0, 1, 2, 3, ... vocab_size]\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size, seq_len, length=1000):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.seq_len = seq_len\n",
    "        self.length = length\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        # Create a random starting point\n",
    "        start = torch.randint(0, self.vocab_size - self.seq_len - 1, (1,)).item()\n",
    "        \n",
    "        # Generate a sequence of consecutive numbers: [10, 11, 12, 13...]\n",
    "        data = torch.arange(start, start + self.seq_len + 1, dtype=torch.long)\n",
    "        \n",
    "        # x is the input: [10, 11, 12]\n",
    "        # y is the target: [11, 12, 13] (shifted by 1)\n",
    "        x = data[:-1]\n",
    "        y = data[1:]\n",
    "        return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "030849e7-991a-4923-9fd6-382bc435fbeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on: cpu\n",
      "Model built successfully.\n"
     ]
    }
   ],
   "source": [
    "config = Config(vocab_size=100, embed_size=64, seq_len=8, n_layer=2, h=2, d_ff=128, total_epochs=5, lr=1e-3, dropout=0.0)    \n",
    "print(f\"Running on: {config.device}\")\n",
    "\n",
    "model = GPT.build_gpt(config)\n",
    "print(\"Model built successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94f57cb5-408f-4f36-a721-ef1dcb7d7e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: torch.Size([32, 8])\n",
      "y: torch.Size([32, 8])\n"
     ]
    }
   ],
   "source": [
    "dataset = NumberSequenceDataset(config.vocab_size, config.seq_len, length=500)\n",
    "train_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "batch = next(iter(train_loader))\n",
    "print(f\"x: {batch[0].shape}\\ny: {batch[1].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a8ca41a-d25f-4da5-8216-93faa5b47ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0/5: 100%|███████████████████████████| 16/16 [00:00<00:00, 67.23it/s, loss=4.12]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/5 Loss: 4.429825156927109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1/5: 100%|███████████████████████████| 16/16 [00:00<00:00, 75.80it/s, loss=3.18]\n",
      "2/5: 100%|███████████████████████████| 16/16 [00:00<00:00, 79.77it/s, loss=2.37]\n",
      "3/5: 100%|███████████████████████████| 16/16 [00:00<00:00, 66.00it/s, loss=1.73]\n",
      "4/5: 100%|███████████████████████████| 16/16 [00:00<00:00, 69.97it/s, loss=1.25]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nStarting Training...\")\n",
    "try:\n",
    "    model.train_gpt(train_loader)\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Training interrupted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8571d4c-e70f-4572-b57c-9f968952e89a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Generation Test...\n",
      "Input: [10]\n",
      "Generated: [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
      "\n",
      "SUCCESS: The model learned to count!\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nStarting Generation Test...\")\n",
    "model.eval()\n",
    "\n",
    "# Start with number [10]\n",
    "# It should generate [11, 12, 13, 14...]\n",
    "start_token = torch.tensor([[10]], dtype=torch.long).to(config.device)\n",
    "\n",
    "# Generate 15 new tokens\n",
    "generated = model.generate(start_token, max_new_token=15, top_k=1)\n",
    "\n",
    "# Convert to simple list for printing\n",
    "result = generated[0].tolist()\n",
    "\n",
    "print(f\"Input: [10]\")\n",
    "print(f\"Generated: {result}\")\n",
    "\n",
    "# Verification\n",
    "if result == list(range(10, 10 + 1 + 15)):\n",
    "    print(\"\\nSUCCESS: The model learned to count!\")\n",
    "else:\n",
    "    print(\"\\nPARTIAL: The model produced valid output but maybe not perfect counting yet.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
